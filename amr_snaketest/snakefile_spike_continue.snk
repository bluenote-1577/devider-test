import yaml
out_dir = "results_spike"
algo = ['rvhaplo', 'dbghaplo', 'igda', 'cliqueSNV']
# Load the config file
with open("./auto_config_megares_deduplicated_for_spike.yaml", "r") as f:
    config = yaml.safe_load(f)

# List of instances
args = [x['arg'] for x in config['instances']]
db = "./clean_megares.fasta"
spike_reads = "./19122017_mousegut_pacbio_scaffolds/2018.02.13_14.02.01_sample_0/reads/anonymous_reads.fq"

rule all:
    input:
        #expand("floria_{arg}", arg=args),
        #expand("tagged_{arg}", arg=args)
        expand("results_spike/{arg}_{alg}/results_spike.txt", arg=args, alg=algo),
        expand("results_spike/{arg}_{alg}/results_spike.bam", arg=args, alg=algo),


rule cat_refs:
    input:
        expand("data_spike/{genome}.fasta", genome=args)
    output:
        "data_spike/cat_ref.fasta"
    run:
        shell("cat {input} > {output}")


for instance in config['instances']:
        
    rule:
        name: f"clean_genome_{instance['arg']}"
        input:
            "data_spike/" + instance['arg'] + ".fasta"
        output:
            "data_spike/" + instance['arg'] + ".cleaned.fasta"
        conda:
            "envs/igda.yaml"
        shell:
            """
            fasta2upper {input} {input}.cleaned;
            fastaclean {input}.cleaned {output}; 
            """
    
    rule:
        name: f"run_rvhaplo_{instance['arg']}"
        input:
            expand("data_spike/{arg}.bam", arg=instance['arg']),
        output:
            expand("results_spike/{arg}_rvhaplo/results_spike.txt", arg=instance['arg'])
        conda:
            "envs/rvhaplo.yaml"
        params:
            out = expand(out_dir + "/{arg}_rvhaplo", arg=instance['arg']),
            ref_genome = db,
            time_file = expand("benchmarks/{arg}_rvhaplo.benchmark.usrbintime", arg=instance['arg'])
        threads:
            10
        shell:
            "cd RVHaplo; /usr/bin/time -v -o ../{params.time_file} ./rvhaplo.sh -i ../{input} -o ../{params.out} -r ../{params.ref_genome} -t 10; cd ..; mv {params.out}/*haplotypes.fasta {output}"


    rule:
        name: f"run_dbghaplo_{instance['arg']}"
        input:
            bam = expand("data_spike/{arg}.bam", arg=instance['arg']),
            vcf = expand("data_spike/{arg}.vcf.gz", arg=instance['arg'])
        output:
            expand(out_dir + "/{arg}_dbghaplo/results_spike.txt", arg=instance['arg'])
        params:
            ref_genome = db,
            out = expand(out_dir + "/{arg}_dbghaplo", arg=instance['arg']),
            time_file = expand("benchmarks/{arg}_dbghaplo.benchmark.usrbintime", arg=instance['arg'])
        threads:
            1
        shell:
            """
            /usr/bin/time -v -o {params.time_file} dbghap -b {input.bam} -v {input.vcf} -o {params.out} -t 1 -r {params.ref_genome} --overwrite;
            cp {params.out}/majority_vote_haplotypes.fasta {output}
            """

    rule:
        name: f"run_igda_{instance['arg']}"
        input:
            ref_gn = "data_spike/" + instance['arg'] + ".cleaned.fasta",
            bam = expand("data_spike/{arg}.bam", arg=instance['arg'])
        output:
            expand("results_spike/{arg}_igda/results_spike.txt", arg=instance['arg'])
        conda:
            "envs/igda.yaml"
        params:
            out = expand(out_dir + "/{arg}_igda", arg=instance['arg']),
            time_file = expand("benchmarks/{arg}_igda.benchmark.usrbintime", arg=instance['arg'])
        threads:
            10
        shell:
            """
            /usr/bin/time -v -o {params.time_file} /bin/sh -c '
            igda_align_ont {input.bam} {input.ref_gn} {params.out}.sam 10;
            sam2bam {params.out}.sam {params.out}.bam;
            igda_pipe_detect -l 300 -m ont {params.out}.bam {input.ref_gn} ./igda_contextmodel/ont/ont_context_effect_read_qv_12_base_qv_12 {params.out}_igda_detect;
            rm -r {params.out};
            igda_pipe_phase -m ont -n 10 {params.out}_igda_detect {input.ref_gn} {params.out};
            cp {params.out}/*.fa {output}'
            """
    
    rule:
        name: f"results_spike_to_bam_{instance['arg']}"
        input:
            expand("results_spike/{arg}_{alg}/results_spike.txt", arg=instance['arg'], alg=algo),
        output:
            expand("results_spike/{arg}_{alg}/results_spike.bam", arg=instance['arg'], alg=algo),
        params: 
            ref_genome = 'data_spike/' + instance['arg'] + '.fasta'
        run:
            for i in range(len(input)):
                shell(f"minimap2 --MD -a {params.ref_genome} {input[i]} | samtools sort -o {output[i]}; samtools index {output[i]}")


    rule:
        name: f"run_cliqueSNV_{instance['arg']}"
        input:
            expand("data_spike/{arg}.bam", arg=instance['arg'])
        output:
            expand(out_dir + "/{arg}_cliqueSNV/results_spike.txt", arg=instance['arg'])
        params:
            out = expand(out_dir + "/{arg}_cliqueSNV", arg=instance['arg']),
            ref_genome = 'data_spike/' + instance['arg'] + '.fasta',
            time_file = expand("benchmarks/{arg}_cliqueSNV.benchmark.usrbintime", arg=instance['arg'])
        threads:
            10
        shell:
            """
            /usr/bin/time -v -o {params.time_file} java -jar clique-snv.jar -m snv-pacbio -in {input} -outDir {params.out} -threads 10;
            mv {params.out}/*.fasta {output}
            """ 

