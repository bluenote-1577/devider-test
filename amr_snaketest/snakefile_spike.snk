import yaml
out_dir = "results_spike"
algo = ['rvhaplo', 'dbghaplo', 'igda', 'cliqueSNV']
# Load the config file
with open("./auto_config_megares_deduplicated_for_spike.yaml", "r") as f:
    config = yaml.safe_load(f)

# List of instances
args = [x['arg'] for x in config['instances']]
db = "./clean_megares.fasta"
spike_reads = "./19122017_mousegut_pacbio_scaffolds/2018.02.13_14.02.01_sample_0/reads/anonymous_reads.fq"

rule all:
    input:
        #expand("floria_{arg}", arg=args),
        #expand("tagged_{arg}", arg=args)
        expand("results_spike/{arg}_{alg}/results_spike.txt", arg=args, alg=algo),
        expand("results_spike/{arg}_{alg}/results_spike.bam", arg=args, alg=algo),
        expand("data_spike/{arg}_true.vcf.gz", arg=args)


rule cat_refs:
    input:
        expand("data_spike/{genome}.fasta", genome=args)
    output:
        "data_spike/cat_ref.fasta"
    run:
        shell("cat {input} > {output}")

rule cat_reads_with_spike:
    input:
        fastq = spike_reads,
        all_fastq = expand("data_spike/{arg}.fastq", arg=args)
    output:
        "data_spike/all.fastq"
    run:
        shell("cat {input.fastq} {input.all_fastq} > {output}")

rule:
    name: f"minimap_all"
    input:
        cat_ref = "data_spike/cat_ref.fasta",
        fastq = "data_spike/all.fastq"
    output:
        "data_spike/all.bam"
    threads:
        10
    run:
        shell("minimap2 -t 10 -ax map-ont {input.cat_ref} {input.fastq} | samtools sort -@ 10 -o {output}")
        shell("samtools index {output}")


for instance in config['instances']:
    rule:
        name: f"extract_{instance['arg']}"
        input:
            fasta= db
        output:
            expand("data_spike/{genome}.fasta", genome=instance['genomes'])
        params:
            genomes=instance['genomes']
        run:
            for genome in params.genomes:
                gn_esc = genome.replace("|", "\|")
                shell("samtools faidx {input.fasta} {gn_esc} > data_spike/{gn_esc}.fasta")

    rule:
        name: f"make_fastq_{instance['arg']}"
        input:
            expand("data_spike/{genome}.fasta", genome=instance['genomes'])
        output:
            expand("data_spike/{arg}.fastq", arg = instance['arg'])
        params:
            cov = instance['coverages']
        run:
            for i in range(len(input)):
                gn_esc = input[i].replace("|", "\|")
                cov = params.cov[i]
                shell("badread simulate --quantity {cov}x --length 1500,200 --reference {gn_esc} >> {output}")
    
    rule:
        name: f"get_bam_from_samtools_{instance['arg']}"
        input:
            expand("data_spike/all.bam")
        output:
            expand("data_spike/{arg}.bam", arg=instance['arg']),
        params:
            curr_arg = instance['arg'],
            base = "data_spike/" + instance['arg']
        run: 
            shell("samtools view -H {input} | grep -E '@HD|@PG|@RG|@CO|@SQ.*SN:{params.curr_arg}' > {params.base}_temp.sam")
            shell("samtools view {input} {params.curr_arg} >> {params.base}_temp.sam")
            shell("samtools view -bh {params.base}_temp.sam > {output}")
            shell("samtools index {output}")
            shell("rm {params.base}_temp.sam")
            
    rule:
        name: f"lofreq_{instance['arg']}"
        input:
            bam = expand("data_spike/{arg}.bam", arg=instance['arg']),
            ref = db
        output:
            vcf = expand("data_spike/{arg}.vcf.gz", arg=instance['arg'])
        params:
            temp1 = temp(expand("data_spike/temp{arg}.vcf", arg=instance['arg'])),
            temp = expand("data_spike/{arg}.vcf", arg=instance['arg']),
            usrbintime = expand("benchmarks/{arg}_lofreq.usrbintime", arg=instance['arg'])
        run:
            shell("/usr/bin/time -v -o {params.usrbintime} ./lofreq_star-2.1.4_linux-x86-64/bin/lofreq call -B -f {input.ref} {input.bam} -o {params.temp} --force-overwrite")
            #get only alleles with AF > 0.1 and < 0.9
            shell("bgzip {params.temp}")
            shell("bcftools index {output}")
    
    rule:
        name: f"clean_genome_{instance['arg']}"
        input:
            "data_spike/" + instance['arg'] + ".fasta"
        output:
            "data_spike/" + instance['arg'] + ".cleaned.fasta"
        conda:
            "envs/igda.yaml"
        shell:
            """
            fasta2upper {input} {input}.cleaned;
            fastaclean {input}.cleaned {output}; 
            """
    
    rule:
        name: f"run_rvhaplo_{instance['arg']}"
        input:
            expand("data_spike/{arg}.bam", arg=instance['arg']),
        output:
            expand("results_spike/{arg}_rvhaplo/results_spike.txt", arg=instance['arg'])
        conda:
            "envs/rvhaplo.yaml"
        params:
            out = expand(out_dir + "/{arg}_rvhaplo", arg=instance['arg']),
            ref_genome = db,
            time_file = expand("benchmarks/{arg}_rvhaplo.benchmark.usrbintime", arg=instance['arg'])
        threads:
            10
        shell:
            "cd RVHaplo; /usr/bin/time -v -o ../{params.time_file} ./rvhaplo.sh -i ../{input} -o ../{params.out} -r ../{params.ref_genome} -t 10; cd ..; mv {params.out}/*haplotypes.fasta {output}"


    rule:
        name: f"run_dbghaplo_{instance['arg']}"
        input:
            bam = expand("data_spike/{arg}.bam", arg=instance['arg']),
            vcf = expand("data_spike/{arg}.vcf.gz", arg=instance['arg'])
        output:
            expand(out_dir + "/{arg}_dbghaplo/results_spike.txt", arg=instance['arg'])
        params:
            ref_genome = db,
            out = expand(out_dir + "/{arg}_dbghaplo", arg=instance['arg']),
            time_file = expand("benchmarks/{arg}_dbghaplo.benchmark.usrbintime", arg=instance['arg'])
        threads:
            1
        shell:
            """
            /usr/bin/time -v -o {params.time_file} dbghap -b {input.bam} -v {input.vcf} -o {params.out} -t 1 -r {params.ref_genome} --overwrite;
            cp {params.out}/majority_vote_haplotypes.fasta {output}
            """

    rule:
        name: f"run_igda_{instance['arg']}"
        input:
            ref_gn = "data_spike/" + instance['arg'] + ".cleaned.fasta",
            bam = expand("data_spike/{arg}.bam", arg=instance['arg'])
        output:
            expand("results_spike/{arg}_igda/results_spike.txt", arg=instance['arg'])
        conda:
            "envs/igda.yaml"
        params:
            out = expand(out_dir + "/{arg}_igda", arg=instance['arg']),
            time_file = expand("benchmarks/{arg}_igda.benchmark.usrbintime", arg=instance['arg'])
        threads:
            10
        shell:
            """
            /usr/bin/time -v -o {params.time_file} /bin/sh -c '
            igda_align_ont {input.bam} {input.ref_gn} {params.out}.sam 10;
            sam2bam {params.out}.sam {params.out}.bam;
            igda_pipe_detect -l 300 -m ont {params.out}.bam {input.ref_gn} ./igda_contextmodel/ont/ont_context_effect_read_qv_12_base_qv_12 {params.out}_igda_detect;
            rm -r {params.out};
            igda_pipe_phase -m ont -n 10 {params.out}_igda_detect {input.ref_gn} {params.out};
            cp {params.out}/*.fa {output}'
            """
    
    rule:
        name: f"get_true_vcf_{instance['arg']}"
        input: 
            genomes = expand("data_spike/{genome}.fasta", genome=instance['genomes']),
            ref_gn = expand("data_spike/{arg}.fasta", arg=instance['arg'])
        output:
            vcf = "data_spike/" + instance['arg'] + "_true.vcf.gz",
            true_bam = "data_spike/" + instance['arg'] + "_true.bam"
        params:
            vcf_prior = "data_spike/" + instance['arg'] + "_true.vcf"
        run:
            gn_escs = []
            for genome in input.genomes:
                gn_esc = genome.replace("|", "\|")
                gn_escs.append(gn_esc)
                
            shell("minimap2 --MD -a  {input.ref_gn} {gn_escs} | samtools sort -o {output.true_bam}; samtools index {output.true_bam}");
            shell("python scripts/snps_from_bam.py {output.true_bam} {input.ref_gn} {params.vcf_prior}");
            shell("bgzip {params.vcf_prior}; bcftools index {params.vcf_prior}.gz -f");

    rule:
        name: f"results_spike_to_bam_{instance['arg']}"
        input:
            expand("results_spike/{arg}_{alg}/results_spike.txt", arg=instance['arg'], alg=algo),
        output:
            expand("results_spike/{arg}_{alg}/results_spike.bam", arg=instance['arg'], alg=algo),
        params: 
            ref_genome = 'data_spike/' + instance['arg'] + '.fasta'
        run:
            for i in range(len(input)):
                shell(f"minimap2 --MD -a {params.ref_genome} {input[i]} | samtools sort -o {output[i]}; samtools index {output[i]}")


    rule:
        name: f"run_cliqueSNV_{instance['arg']}"
        input:
            expand("data_spike/{arg}.bam", arg=instance['arg'])
        output:
            expand(out_dir + "/{arg}_cliqueSNV/results_spike.txt", arg=instance['arg'])
        params:
            out = expand(out_dir + "/{arg}_cliqueSNV", arg=instance['arg']),
            ref_genome = 'data_spike/' + instance['arg'] + '.fasta',
            time_file = expand("benchmarks/{arg}_cliqueSNV.benchmark.usrbintime", arg=instance['arg'])
        threads:
            10
        shell:
            """
            /usr/bin/time -v -o {params.time_file} java -jar clique-snv.jar -m snv-pacbio -in {input} -outDir {params.out} -threads 10;
            mv {params.out}/*.fasta {output}
            """ 

